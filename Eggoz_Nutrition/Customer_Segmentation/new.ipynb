{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: schedule in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: snowflake-connector-python in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2022.12.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (23.0)\n",
      "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (41.0.7)\n",
      "Requirement already satisfied: platformdirs<4.0.0,>=2.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (3.0.0)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2.31.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2.7.0)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (1.15.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2.10)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (23.3.0)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (3.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (3.0.1)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: tomlkit in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (4.5.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2022.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0->snowflake-connector-python) (1.26.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install schedule\n",
    "!pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# Snowflake credentials\n",
    "username = 'Harshiteggoz'\n",
    "password = 'Eggoz@123'\n",
    "account = 'wt08714.ap-south-1.aws'\n",
    "warehouse = 'COMPUTE_WH'\n",
    "database = 'EGGOZDB'\n",
    "schema = 'MAPLEMONK'\n",
    "\n",
    "# Connecting to Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user=username,\n",
    "    password=password,\n",
    "    account=account,\n",
    "    warehouse=warehouse,\n",
    "    database=database,\n",
    "    schema=schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4940\\2615130172.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result_df = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0         2022-10-27\n",
      "1         2022-10-18\n",
      "2         2022-10-21\n",
      "3         2022-10-21\n",
      "4         2022-10-21\n",
      "             ...    \n",
      "799800    2023-07-05\n",
      "799801    2023-06-15\n",
      "799802    2023-06-27\n",
      "799803    2023-06-28\n",
      "799804    2022-02-15\n",
      "Name: DATE, Length: 799805, dtype: object\n"
     ]
    }
   ],
   "source": [
    "query=      \"\"\"\n",
    "            SELECT *\n",
    "            FROM eggozdb.maplemonk.darjan_sales_return_replace_promo_primary_and_secondary\n",
    "            \"\"\"\n",
    "cur = conn.cursor()\n",
    "cur.execute(f\"USE {database}.{schema}\")\n",
    "\n",
    "result_df = pd.read_sql_query(query, conn)\n",
    "print(\"\\n\",result_df['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns of object type\n",
    "object_columns = result_df.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RETAILER_NAME', 'ONBOARDING_STATUS', 'DATE', 'PARENT_RETAILER_NAME',\n",
       "       'AREA_CLASSIFICATION', 'CITY_NAME', 'BRAND_TYPE', 'SHORT_NAME', 'SKU',\n",
       "       'PRODUCT_TYPE', 'PRODUCT_NAME', 'RETAILER_CATEGORY', 'SALE_TYPE',\n",
       "       'DISTRIBUTOR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object columns to datetime\n",
    "for col in object_columns:\n",
    "    try:\n",
    "        converted_values = pd.to_datetime(result_df[col], errors='coerce')\n",
    "        if converted_values.notna().any():\n",
    "            result_df[col] = converted_values\n",
    "    except ValueError:\n",
    "        # Handle any specific errors that might occur during conversion\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RETAILER_NAME</th>\n",
       "      <th>ONBOARDING_STATUS</th>\n",
       "      <th>DATE</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>SKU_ORDER_PRICE_AMOUNT</th>\n",
       "      <th>NET_SALE</th>\n",
       "      <th>PARENT_RETAILER_NAME</th>\n",
       "      <th>AREA_CLASSIFICATION</th>\n",
       "      <th>CITY_NAME</th>\n",
       "      <th>BEAT_NUMBER</th>\n",
       "      <th>...</th>\n",
       "      <th>RETURN_EGGS</th>\n",
       "      <th>REPLACED_EGGS</th>\n",
       "      <th>PROMO_EGGS</th>\n",
       "      <th>SINGLE_SKU_RATE</th>\n",
       "      <th>EGGS</th>\n",
       "      <th>RETAILER_CATEGORY</th>\n",
       "      <th>SALE_TYPE</th>\n",
       "      <th>RETAILER_ID</th>\n",
       "      <th>DISTRIBUTOR_ID</th>\n",
       "      <th>DISTRIBUTOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F3122* Singla provison store</td>\n",
       "      <td>Cold</td>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon-GT</td>\n",
       "      <td>Faridabad</td>\n",
       "      <td>3006.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>General Trader</td>\n",
       "      <td>Secondary_Sale</td>\n",
       "      <td>6003.0</td>\n",
       "      <td>4694.0</td>\n",
       "      <td>G2447* Anushka sales Agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F3070* Amit store</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2022-10-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon-GT</td>\n",
       "      <td>Faridabad</td>\n",
       "      <td>3006.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>General Trader</td>\n",
       "      <td>Secondary_Sale</td>\n",
       "      <td>5638.0</td>\n",
       "      <td>4694.0</td>\n",
       "      <td>G2447* Anushka sales Agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F3003* AVNOOR ENTERPRISES</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>4.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon-GT</td>\n",
       "      <td>Faridabad</td>\n",
       "      <td>5052.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>General Trader</td>\n",
       "      <td>Secondary_Sale</td>\n",
       "      <td>507.0</td>\n",
       "      <td>4694.0</td>\n",
       "      <td>G2447* Anushka sales Agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F3020* The daily mart(Faridabad)</td>\n",
       "      <td>Closed</td>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon-GT</td>\n",
       "      <td>Faridabad</td>\n",
       "      <td>5050.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>General Trader</td>\n",
       "      <td>Secondary_Sale</td>\n",
       "      <td>812.0</td>\n",
       "      <td>4694.0</td>\n",
       "      <td>G2447* Anushka sales Agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F3132* Daga Departmental store</td>\n",
       "      <td>Cold</td>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Gurgaon-GT</td>\n",
       "      <td>Faridabad</td>\n",
       "      <td>3006.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>General Trader</td>\n",
       "      <td>Secondary_Sale</td>\n",
       "      <td>6021.0</td>\n",
       "      <td>4694.0</td>\n",
       "      <td>G2447* Anushka sales Agency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      RETAILER_NAME ONBOARDING_STATUS       DATE  QUANTITY  \\\n",
       "0      F3122* Singla provison store              Cold 2022-10-27       1.0   \n",
       "1                F3070* Amit store             Closed 2022-10-18       1.0   \n",
       "2         F3003* AVNOOR ENTERPRISES            Closed 2022-10-21       4.0   \n",
       "3  F3020* The daily mart(Faridabad)            Closed 2022-10-21       0.0   \n",
       "4   F3132* Daga Departmental store               Cold 2022-10-21       0.0   \n",
       "\n",
       "   SKU_ORDER_PRICE_AMOUNT  NET_SALE PARENT_RETAILER_NAME AREA_CLASSIFICATION  \\\n",
       "0                   135.0     135.0                 None          Gurgaon-GT   \n",
       "1                   144.0     144.0                 None          Gurgaon-GT   \n",
       "2                   436.0     436.0                 None          Gurgaon-GT   \n",
       "3                     0.0       0.0                 None          Gurgaon-GT   \n",
       "4                     0.0       0.0                 None          Gurgaon-GT   \n",
       "\n",
       "   CITY_NAME  BEAT_NUMBER  ...  RETURN_EGGS REPLACED_EGGS  PROMO_EGGS  \\\n",
       "0  Faridabad       3006.0  ...          0.0          10.0         0.0   \n",
       "1  Faridabad       3006.0  ...          0.0          20.0         0.0   \n",
       "2  Faridabad       5052.0  ...          0.0          10.0         0.0   \n",
       "3  Faridabad       5050.0  ...          0.0          12.0         0.0   \n",
       "4  Faridabad       3006.0  ...          0.0          12.0         0.0   \n",
       "\n",
       "   SINGLE_SKU_RATE  EGGS RETAILER_CATEGORY       SALE_TYPE RETAILER_ID  \\\n",
       "0            135.0  10.0    General Trader  Secondary_Sale      6003.0   \n",
       "1            144.0  10.0    General Trader  Secondary_Sale      5638.0   \n",
       "2             89.0  40.0    General Trader  Secondary_Sale       507.0   \n",
       "3              0.0   0.0    General Trader  Secondary_Sale       812.0   \n",
       "4              0.0   0.0    General Trader  Secondary_Sale      6021.0   \n",
       "\n",
       "  DISTRIBUTOR_ID                  DISTRIBUTOR  \n",
       "0         4694.0  G2447* Anushka sales Agency  \n",
       "1         4694.0  G2447* Anushka sales Agency  \n",
       "2         4694.0  G2447* Anushka sales Agency  \n",
       "3         4694.0  G2447* Anushka sales Agency  \n",
       "4         4694.0  G2447* Anushka sales Agency  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 799805 entries, 0 to 799804\n",
      "Data columns (total 29 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   RETAILER_NAME           799805 non-null  object        \n",
      " 1   ONBOARDING_STATUS       799805 non-null  object        \n",
      " 2   DATE                    799804 non-null  datetime64[ns]\n",
      " 3   QUANTITY                799805 non-null  float64       \n",
      " 4   SKU_ORDER_PRICE_AMOUNT  799805 non-null  float64       \n",
      " 5   NET_SALE                799805 non-null  float64       \n",
      " 6   PARENT_RETAILER_NAME    339351 non-null  object        \n",
      " 7   AREA_CLASSIFICATION     799805 non-null  object        \n",
      " 8   CITY_NAME               799805 non-null  object        \n",
      " 9   BEAT_NUMBER             799805 non-null  float64       \n",
      " 10  BEAT_NUMBER_OPERATIONS  666506 non-null  float64       \n",
      " 11  BRAND_TYPE              675406 non-null  object        \n",
      " 12  ORDER_PRICE_AMOUNT      675406 non-null  float64       \n",
      " 13  SKU_RETURN_AMOUNT       799805 non-null  float64       \n",
      " 14  SKU_COUNT               799805 non-null  float64       \n",
      " 15  SHORT_NAME              799805 non-null  object        \n",
      " 16  SKU                     799805 non-null  object        \n",
      " 17  PRODUCT_TYPE            799805 non-null  object        \n",
      " 18  PRODUCT_NAME            799805 non-null  object        \n",
      " 19  RETURN_EGGS             799805 non-null  float64       \n",
      " 20  REPLACED_EGGS           799805 non-null  float64       \n",
      " 21  PROMO_EGGS              799805 non-null  float64       \n",
      " 22  SINGLE_SKU_RATE         799805 non-null  float64       \n",
      " 23  EGGS                    799805 non-null  float64       \n",
      " 24  RETAILER_CATEGORY       799805 non-null  object        \n",
      " 25  SALE_TYPE               799805 non-null  object        \n",
      " 26  RETAILER_ID             799805 non-null  float64       \n",
      " 27  DISTRIBUTOR_ID          283484 non-null  float64       \n",
      " 28  DISTRIBUTOR             283484 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(15), object(13)\n",
      "memory usage: 177.0+ MB\n"
     ]
    }
   ],
   "source": [
    "result_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m emails_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mEggoz\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mData_Sales\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124memails.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Open the Excel file in 'a' (append) mode using openpyxl engine\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_excel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(query):\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;66;03m# Execute Snowflake SQL Queries\u001b[39;00m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# Connecting to Snowflake\u001b[39;00m\n\u001b[0;32m     30\u001b[0m         conn \u001b[38;5;241m=\u001b[39m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[0;32m     31\u001b[0m             user\u001b[38;5;241m=\u001b[39musername,\n\u001b[0;32m     32\u001b[0m             password\u001b[38;5;241m=\u001b[39mpassword,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m             schema\u001b[38;5;241m=\u001b[39mschema\n\u001b[0;32m     37\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\excel\\_openpyxl.py:73\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_workbook\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_book \u001b[38;5;241m=\u001b[39m load_workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs)\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# Create workbook object with default optimized_write=True.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openpyxl\\reader\\excel.py:344\u001b[0m, in \u001b[0;36mload_workbook\u001b[1;34m(filename, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_workbook\u001b[39m(filename, read_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_vba\u001b[38;5;241m=\u001b[39mKEEP_VBA,\n\u001b[0;32m    315\u001b[0m                   data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_links\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rich_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Open the given filename and return the workbook\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    :param filename: the path to open or a file-like object\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    342\u001b[0m \n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43mExcelReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vba\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdata_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrich_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m     reader\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mwb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openpyxl\\reader\\excel.py:123\u001b[0m, in \u001b[0;36mExcelReader.__init__\u001b[1;34m(self, fn, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, read_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_vba\u001b[38;5;241m=\u001b[39mKEEP_VBA,\n\u001b[0;32m    122\u001b[0m              data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_links\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rich_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marchive \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marchive\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_only \u001b[38;5;241m=\u001b[39m read_only\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openpyxl\\reader\\excel.py:95\u001b[0m, in \u001b[0;36m_validate_archive\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     88\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl does not support \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m file format, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease check you can open \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mit with Excel first. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupported formats are: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m%\u001b[39m (file_format,\n\u001b[0;32m     92\u001b[0m                                                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(SUPPORTED_FORMATS))\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidFileException(msg)\n\u001b[1;32m---> 95\u001b[0m archive \u001b[38;5;241m=\u001b[39m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m archive\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\zipfile.py:1258\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1258\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1261\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1262\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\zipfile.py:1325\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# Snowflake credentials\n",
    "username = 'Harshiteggoz'\n",
    "password = 'Eggoz@123'\n",
    "account = 'wt08714.ap-south-1.aws'\n",
    "warehouse = 'COMPUTE_WH'\n",
    "database = 'EGGOZDB'\n",
    "schema = 'MAPLEMONK'\n",
    "\n",
    "# Email credentials\n",
    "sender_email = 'abhishektiwari.nssc@gmail.com'\n",
    "app_password = 'rpax rxpp mpws wzvb'\n",
    "output_excel_file = 'transformed_data_output.xlsx'  # Use the same file for all recipients\n",
    "\n",
    "# Read emails and names from CSV\n",
    "emails_df = pd.read_csv('C:\\\\Users\\\\User\\\\Downloads\\\\Eggoz\\\\Data_Sales\\\\emails.csv')\n",
    "\n",
    "# Open the Excel file in 'a' (append) mode using openpyxl engine\n",
    "with pd.ExcelWriter(output_excel_file, engine='openpyxl', mode='a') as writer:\n",
    "    def transform(query):\n",
    "        # Execute Snowflake SQL Queries\n",
    "        # Connecting to Snowflake\n",
    "        conn = snowflake.connector.connect(\n",
    "            user=username,\n",
    "            password=password,\n",
    "            account=account,\n",
    "            warehouse=warehouse,\n",
    "            database=database,\n",
    "            schema=schema\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"USE {database}.{schema}\")\n",
    "\n",
    "        result_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "        # Identify columns of object type\n",
    "        object_columns = result_df.select_dtypes(include='object').columns\n",
    "\n",
    "        # Convert object columns to datetime\n",
    "        for col in object_columns:\n",
    "            try:\n",
    "                converted_values = pd.to_datetime(result_df[col], errors='coerce')\n",
    "                if converted_values.notna().any():\n",
    "                    result_df[col] = converted_values\n",
    "            except ValueError:\n",
    "                # Handle any specific errors that might occur during conversion\n",
    "                pass\n",
    "        return result_df\n",
    "    def send_email(name, email):\n",
    "        # Create Excel attachment\n",
    "        with open(output_excel_file, 'rb') as file:\n",
    "            excel_attachment = MIMEText(file.read(), 'base64', 'utf-8')\n",
    "            excel_attachment.add_header('Content-Disposition', 'attachment', filename='transformed_data_output.xlsx')\n",
    "\n",
    "        # Create email message\n",
    "        email_message = MIMEMultipart()\n",
    "        email_message['From'] = sender_email\n",
    "        email_message['To'] = email\n",
    "        email_message['Subject'] = 'Transformed Data'\n",
    "        email_message.attach(excel_attachment)\n",
    "\n",
    "        # Customize email body\n",
    "        email_body = f\"Hi {name},\\nPlease find attached the transformed dataset\\nThanks\"\n",
    "        email_message.attach(MIMEText(email_body, 'plain'))\n",
    "\n",
    "        # Send email using SMTP\n",
    "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, app_password)\n",
    "            server.sendmail(sender_email, email, email_message.as_string())\n",
    "\n",
    "    def fetch_transform_send():\n",
    "        # Define queries for each sheet with specific columns\n",
    "        queries = [\n",
    "            \"\"\"\n",
    "            SELECT ID, NAME\n",
    "            FROM eggozdb.maplemonk.my_sql_product_product\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            SELECT ID, CODE\n",
    "            FROM eggozdb.maplemonk.my_sql_retailer_retailer\n",
    "            \"\"\",\n",
    "             \"\"\"\n",
    "            SELECT DATE, SKU_ORDER_PRICE_AMOUNT\n",
    "            FROM eggozdb.maplemonk.darjan_sales_return_replace_promo_primary_and_secondary\n",
    "            \"\"\"\n",
    "        ]\n",
    "\n",
    "        # Iterate over queries and send emails\n",
    "        for sheet_index, query in enumerate(queries, start=1):\n",
    "            result_df = transform(query)\n",
    "\n",
    "            # Save DataFrame to the current sheet\n",
    "            excel_sheet_name = f'Sheet{sheet_index}'\n",
    "\n",
    "            # Check if the sheet already exists\n",
    "            if excel_sheet_name in writer.sheets:\n",
    "                # If the sheet exists, you can choose to overwrite or use a different name\n",
    "                excel_sheet_name += \"_new\"  # Use a different name (you can customize this logic)\n",
    "\n",
    "            result_df.to_excel(writer, sheet_name=excel_sheet_name, index=False)\n",
    "\n",
    "        # Send customized emails to each recipient for the current sheet\n",
    "        for index, row in emails_df.iterrows():\n",
    "            send_email(row['name'], row['email'])\n",
    "\n",
    "        # Close the connection to Snowflake\n",
    "        conn.close()\n",
    "\n",
    "# Schedule the message to be sent every hour\n",
    "schedule.every().minute.do(fetch_transform_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12612\\3879185800.py:51: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result_df = pd.read_sql_query(query, conn)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12612\\3879185800.py:51: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result_df = pd.read_sql_query(query, conn)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12612\\3879185800.py:51: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result_df = pd.read_sql_query(query, conn)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     schedule\u001b[38;5;241m.\u001b[39mrun_pending()\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'email'], dtype='object')\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(emails_df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Open the Excel file in 'a' (append) mode using openpyxl engine\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_excel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(query):\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;66;03m# Execute Snowflake SQL Queries\u001b[39;00m\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;66;03m# Connecting to Snowflake\u001b[39;00m\n\u001b[0;32m     42\u001b[0m         conn \u001b[38;5;241m=\u001b[39m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39mconnect(\n\u001b[0;32m     43\u001b[0m             user\u001b[38;5;241m=\u001b[39musername,\n\u001b[0;32m     44\u001b[0m             password\u001b[38;5;241m=\u001b[39mpassword,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m             schema\u001b[38;5;241m=\u001b[39mschema\n\u001b[0;32m     49\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\excel\\_openpyxl.py:73\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_workbook\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_book \u001b[38;5;241m=\u001b[39m load_workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs)\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# Create workbook object with default optimized_write=True.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openpyxl\\reader\\excel.py:344\u001b[0m, in \u001b[0;36mload_workbook\u001b[1;34m(filename, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_workbook\u001b[39m(filename, read_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_vba\u001b[38;5;241m=\u001b[39mKEEP_VBA,\n\u001b[0;32m    315\u001b[0m                   data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_links\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rich_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Open the given filename and return the workbook\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    :param filename: the path to open or a file-like object\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    342\u001b[0m \n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43mExcelReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_vba\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mdata_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_links\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrich_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m     reader\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reader\u001b[38;5;241m.\u001b[39mwb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openpyxl\\reader\\excel.py:123\u001b[0m, in \u001b[0;36mExcelReader.__init__\u001b[1;34m(self, fn, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, read_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_vba\u001b[38;5;241m=\u001b[39mKEEP_VBA,\n\u001b[0;32m    122\u001b[0m              data_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, keep_links\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rich_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marchive \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marchive\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_only \u001b[38;5;241m=\u001b[39m read_only\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openpyxl\\reader\\excel.py:95\u001b[0m, in \u001b[0;36m_validate_archive\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     88\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenpyxl does not support \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m file format, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     89\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease check you can open \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mit with Excel first. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupported formats are: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m%\u001b[39m (file_format,\n\u001b[0;32m     92\u001b[0m                                                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(SUPPORTED_FORMATS))\n\u001b[0;32m     93\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidFileException(msg)\n\u001b[1;32m---> 95\u001b[0m archive \u001b[38;5;241m=\u001b[39m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m archive\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\zipfile.py:1258\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1258\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1261\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1262\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\zipfile.py:1325\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# Snowflake credentials\n",
    "username = 'Harshiteggoz'\n",
    "password = 'Eggoz@123'\n",
    "account = 'wt08714.ap-south-1.aws'\n",
    "warehouse = 'COMPUTE_WH'\n",
    "database = 'EGGOZDB'\n",
    "schema = 'MAPLEMONK'\n",
    "\n",
    "# Connecting to Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user=username,\n",
    "    password=password,\n",
    "    account=account,\n",
    "    warehouse=warehouse,\n",
    "    database=database,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "# Email credentials\n",
    "sender_email = 'abhishektiwari.nssc@gmail.com'\n",
    "app_password = 'rpax rxpp mpws wzvb'\n",
    "output_excel_file = 'transformed_data_output.xlsx'  # Use the same file for all recipients\n",
    "\n",
    "# Read emails and names from CSV\n",
    "emails_df = pd.read_csv('C:\\\\Users\\\\User\\\\Downloads\\\\Eggoz\\\\Data_Sales\\\\emails.csv')\n",
    "print(emails_df.columns)\n",
    "\n",
    "# Open the Excel file in 'a' (append) mode using openpyxl engine\n",
    "with pd.ExcelWriter(output_excel_file, engine='openpyxl', mode='a') as writer:\n",
    "\n",
    "    def transform(query):\n",
    "        # Execute Snowflake SQL Queries\n",
    "        # Connecting to Snowflake\n",
    "        conn = snowflake.connector.connect(\n",
    "            user=username,\n",
    "            password=password,\n",
    "            account=account,\n",
    "            warehouse=warehouse,\n",
    "            database=database,\n",
    "            schema=schema\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"USE {database}.{schema}\")\n",
    "\n",
    "        result_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "        # Identify date columns and convert them to date without timezone\n",
    "        date_columns = [col for col in result_df.columns if result_df[col].dtype == 'datetime64[ns, UTC]']\n",
    "\n",
    "        for date_column in date_columns:\n",
    "            # Check if the date column exists before attempting to convert\n",
    "            if date_column in result_df.columns:\n",
    "                result_df[date_column] = result_df[date_column].dt.date\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def send_email(name, email):\n",
    "        # Create Excel attachment\n",
    "        with open(output_excel_file, 'rb') as file:\n",
    "            excel_attachment = MIMEText(file.read(), 'base64', 'utf-8')\n",
    "            excel_attachment.add_header('Content-Disposition', 'attachment', filename='transformed_data_output.xlsx')\n",
    "\n",
    "        # Create email message\n",
    "        email_message = MIMEMultipart()\n",
    "        email_message['From'] = sender_email\n",
    "        email_message['To'] = email\n",
    "        email_message['Subject'] = 'Transformed Data'\n",
    "        email_message.attach(excel_attachment)\n",
    "\n",
    "        # Customize email body\n",
    "        email_body = f\"Hi {name},\\nPlease find attached the transformed dataset\\nThanks\"\n",
    "        email_message.attach(MIMEText(email_body, 'plain'))\n",
    "\n",
    "        # Send email using SMTP\n",
    "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, app_password)\n",
    "            server.sendmail(sender_email, email, email_message.as_string())\n",
    "\n",
    "    def fetch_transform_send():\n",
    "        # Define queries for each sheet with specific columns\n",
    "        queries = [\n",
    "            \"\"\"\n",
    "            SELECT QUANTITY, SKU_ORDER_PRICE_AMOUNT\n",
    "            FROM eggozdb.maplemonk.darjan_sales_return_replace_promo_primary_and_secondary\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            SELECT ID, NAME\n",
    "            FROM eggozdb.maplemonk.my_sql_product_product\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            SELECT ID, CODE\n",
    "            FROM eggozdb.maplemonk.my_sql_retailer_retailer\n",
    "            \"\"\"\n",
    "        ]\n",
    "\n",
    "        # Iterate over queries and send emails\n",
    "        for sheet_index, (query, sheet_name_suffix) in enumerate(zip(queries, [\"Sheet1_akt\", \"Sheet2_abhi\", \"Sheet3_eggoz\"]), start=1):\n",
    "            result_df = transform(query)\n",
    "\n",
    "            # Save DataFrame to the current sheet\n",
    "            excel_sheet_name = f'{sheet_name_suffix}_new{sheet_index}'\n",
    "\n",
    "            # Check if the sheet already exists\n",
    "            if excel_sheet_name in writer.sheets:\n",
    "                # If the sheet exists, you can choose to overwrite or use a different name\n",
    "                excel_sheet_name += \"_new\"  # Use a different name (you can customize this logic)\n",
    "\n",
    "            result_df.to_excel(writer, sheet_name=excel_sheet_name, index=False)\n",
    "\n",
    "            # Send customized emails to each recipient for the current sheet\n",
    "            for index, row in emails_df.iterrows():\n",
    "                send_email(row['name'], row['email'])\n",
    "\n",
    "        # Close the connection to Snowflake\n",
    "        conn.close()\n",
    "\n",
    "# Schedule the message to be sent every hour\n",
    "schedule.every().minute.do(fetch_transform_send)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10736\\1275333277.py:53: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result_df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
