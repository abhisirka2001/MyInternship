{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: schedule in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: snowflake-connector-python in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (3.6.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2022.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (4.5.0)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (1.15.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (23.0)\n",
      "Requirement already satisfied: tomlkit in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (0.12.3)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2.7.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2.10)\n",
      "Requirement already satisfied: platformdirs<4.0.0,>=2.6.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (3.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2022.12.7)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (41.0.7)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (3.9.0)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (23.3.0)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from snowflake-connector-python) (2.31.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0->snowflake-connector-python) (1.26.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -nowflake-connector-python (c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install schedule\n",
    "!pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'email'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Every 1 minute do fetch_transform_send() (last run: [never], next run: 2023-12-22 14:23:50)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import schedule\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# Snowflake credentials\n",
    "username = 'Harshiteggoz'\n",
    "password = 'Eggoz@123'\n",
    "account = 'wt08714.ap-south-1.aws'\n",
    "warehouse = 'COMPUTE_WH'\n",
    "database = 'EGGOZDB'\n",
    "schema = 'MAPLEMONK'\n",
    "\n",
    "# Connecting to Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user=username,\n",
    "    password=password,\n",
    "    account=account,\n",
    "    warehouse=warehouse,\n",
    "    database=database,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "# Email credentials\n",
    "sender_email = 'abhishektiwari.nssc@gmail.com'\n",
    "app_password = 'rpax rxpp mpws wzvb'\n",
    "excel_file_path = 'transformed_data.xlsx'  # Use the same file for all recipients\n",
    "\n",
    "# Read emails and names from CSV\n",
    "emails_df = pd.read_csv('C:\\\\Users\\\\User\\\\Downloads\\\\Eggoz\\\\Data_Sales\\\\emails.csv')\n",
    "print(emails_df.columns)\n",
    "def transform(query):\n",
    "    # Execute Snowflake SQL Queries\n",
    "    # Connecting to Snowflake\n",
    "    conn = snowflake.connector.connect(\n",
    "        user=username,\n",
    "        password=password,\n",
    "        account=account,\n",
    "        warehouse=warehouse,\n",
    "        database=database,\n",
    "        schema=schema\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(f\"USE {database}.{schema}\")\n",
    "\n",
    "    result_df = pd.read_sql_query(query, conn)\n",
    "\n",
    "\n",
    "\n",
    "    return result_df\n",
    "\n",
    "output_excel_file = \"transformed_data_output.xlsx\"\n",
    "\n",
    "def send_email(name, email, excel_file_path):\n",
    "    # Create Excel attachment\n",
    "    with open(excel_file_path, 'rb') as file:\n",
    "        excel_attachment = MIMEText(file.read(), 'base64', 'utf-8')\n",
    "        excel_attachment.add_header('Content-Disposition', 'attachment', filename='transformed_data_output.xlsx')\n",
    "\n",
    "    # Create email message\n",
    "    email_message = MIMEMultipart()\n",
    "    email_message['From'] = sender_email\n",
    "    email_message['To'] = email\n",
    "    email_message['Subject'] = 'Transformed Data'\n",
    "    email_message.attach(excel_attachment)\n",
    "\n",
    "    # Customize email body\n",
    "    email_body = f\"Hi {name},\\nPlease find attached the transformed dataset\\nThanks\"\n",
    "    email_message.attach(MIMEText(email_body, 'plain'))\n",
    "\n",
    "    # Send email using SMTP\n",
    "    with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "        server.starttls()\n",
    "        server.login(sender_email, app_password)\n",
    "        server.sendmail(sender_email, email, email_message.as_string())\n",
    "\n",
    "def fetch_transform_send():\n",
    "    # Define queries for each sheet with specific columns\n",
    "    queries = [\n",
    "        \"\"\"\n",
    "        SELECT QUANTITY, SKU_ORDER_PRICE_AMOUNT\n",
    "        FROM eggozdb.maplemonk.darjan_sales_return_replace_promo_primary_and_secondary\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        SELECT ID, NAME\n",
    "        FROM eggozdb.maplemonk.my_sql_product_product\n",
    "        \"\"\",\n",
    "        \"\"\"\n",
    "        SELECT ID, CODE\n",
    "        FROM eggozdb.maplemonk.my_sql_retailer_retailer\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "    # Iterate over queries and send emails\n",
    "    for sheet_index, query in enumerate(queries, start=1):\n",
    "        result_df = transform(query)\n",
    "        print(result_df.columns)\n",
    "        # Save DataFrame to the current sheet\n",
    "        excel_sheet_name = f'Sheet{sheet_index}'\n",
    "\n",
    "        # Check if the sheet already exists\n",
    "        if excel_sheet_name in writer.sheets:\n",
    "            # If the sheet exists, you can choose to overwrite or use a different name\n",
    "            excel_sheet_name += \"_new\"  # Use a different name (you can customize this logic)\n",
    "\n",
    "        excel_file_path = output_excel_file  # Store the Excel file path for sending email\n",
    "        with pd.ExcelWriter(output_excel_file, engine='openpyxl', mode='a') as writer:\n",
    "            result_df.to_excel(writer, sheet_name=excel_sheet_name, index=False)\n",
    "\n",
    "            # Send customized emails to each recipient\n",
    "            for index, row in emails_df.iterrows():\n",
    "                send_email(row['name'], row['email'], excel_file_path)\n",
    "\n",
    "    # Close the connection to Snowflake\n",
    "    conn.close()\n",
    "\n",
    "# Schedule the message to be sent every hour\n",
    "schedule.every().minute.do(fetch_transform_send)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'email'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Every 1 minute do fetch_transform_send() (last run: [never], next run: 2023-12-22 14:53:08)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "import schedule\n",
    "import time\n",
    "\n",
    "# Snowflake credentials\n",
    "username = 'Harshiteggoz'\n",
    "password = 'Eggoz@123'\n",
    "account = 'wt08714.ap-south-1.aws'\n",
    "warehouse = 'COMPUTE_WH'\n",
    "database = 'EGGOZDB'\n",
    "schema = 'MAPLEMONK'\n",
    "\n",
    "# Connecting to Snowflake\n",
    "conn = snowflake.connector.connect(\n",
    "    user=username,\n",
    "    password=password,\n",
    "    account=account,\n",
    "    warehouse=warehouse,\n",
    "    database=database,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "# Email credentials\n",
    "sender_email = 'abhishektiwari.nssc@gmail.com'\n",
    "app_password = 'rpax rxpp mpws wzvb'\n",
    "output_excel_file = 'transformed_data_output.xlsx'  # Use the same file for all recipients\n",
    "\n",
    "# Read emails and names from CSV\n",
    "emails_df = pd.read_csv('C:\\\\Users\\\\User\\\\Downloads\\\\Eggoz\\\\Data_Sales\\\\emails.csv')\n",
    "print(emails_df.columns)\n",
    "\n",
    "# Open the Excel file in 'a' (append) mode using openpyxl engine\n",
    "with pd.ExcelWriter(output_excel_file, engine='openpyxl', mode='a') as writer:\n",
    "    def transform(query):\n",
    "        # Execute Snowflake SQL Queries\n",
    "        # Connecting to Snowflake\n",
    "        conn = snowflake.connector.connect(\n",
    "            user=username,\n",
    "            password=password,\n",
    "            account=account,\n",
    "            warehouse=warehouse,\n",
    "            database=database,\n",
    "            schema=schema\n",
    "        )\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"USE {database}.{schema}\")\n",
    "\n",
    "        result_df = pd.read_sql_query(query, conn)\n",
    "            # Identify date columns and convert them to date without timezone\n",
    "        date_columns = [col for col in result_df.columns if result_df[col].dtype == 'datetime64[ns, UTC]']\n",
    "\n",
    "        for date_column in date_columns:\n",
    "        # Check if the date column exists before attempting to convert\n",
    "           if date_column in result_df.columns:\n",
    "               result_df[date_column] = result_df[date_column].dt.date\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def send_email(name, email):\n",
    "        # Create Excel attachment\n",
    "        with open(output_excel_file, 'rb') as file:\n",
    "            excel_attachment = MIMEText(file.read(), 'base64', 'utf-8')\n",
    "            excel_attachment.add_header('Content-Disposition', 'attachment', filename='transformed_data_output.xlsx')\n",
    "\n",
    "        # Create email message\n",
    "        email_message = MIMEMultipart()\n",
    "        email_message['From'] = sender_email\n",
    "        email_message['To'] = email\n",
    "        email_message['Subject'] = 'Transformed Data'\n",
    "        email_message.attach(excel_attachment)\n",
    "\n",
    "        # Customize email body\n",
    "        email_body = f\"Hi {name},\\nPlease find attached the transformed dataset\\nThanks\"\n",
    "        email_message.attach(MIMEText(email_body, 'plain'))\n",
    "\n",
    "        # Send email using SMTP\n",
    "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(sender_email, app_password)\n",
    "            server.sendmail(sender_email, email, email_message.as_string())\n",
    "\n",
    "    def fetch_transform_send():\n",
    "        # Define queries for each sheet with specific columns\n",
    "        queries = [\n",
    "            \"\"\"\n",
    "            SELECT DATE, SKU_ORDER_PRICE_AMOUNT\n",
    "            FROM eggozdb.maplemonk.darjan_sales_return_replace_promo_primary_and_secondary\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            SELECT ID, NAME\n",
    "            FROM eggozdb.maplemonk.my_sql_product_product\n",
    "            \"\"\",\n",
    "            \"\"\"\n",
    "            SELECT ID, CODE\n",
    "            FROM eggozdb.maplemonk.my_sql_retailer_retailer\n",
    "            \"\"\"\n",
    "        ]\n",
    "\n",
    "        # Iterate over queries and send emails\n",
    "        for sheet_index, query in enumerate(queries, start=1):\n",
    "            result_df = transform(query)\n",
    "\n",
    "            # Save DataFrame to the current sheet\n",
    "            excel_sheet_name = f'Sheet{sheet_index}'\n",
    "\n",
    "            # Check if the sheet already exists\n",
    "            if excel_sheet_name in writer.sheets:\n",
    "                # If the sheet exists, you can choose to overwrite or use a different name\n",
    "                excel_sheet_name += \"_new\"  # Use a different name (you can customize this logic)\n",
    "\n",
    "            result_df.to_excel(writer, sheet_name=excel_sheet_name, index=False)\n",
    "\n",
    "            # Send customized emails to each recipient for the current sheet\n",
    "            for index, row in emails_df.iterrows():\n",
    "                send_email(row['name'], row['email'])\n",
    "\n",
    "        # Close the connection to Snowflake\n",
    "        conn.close()\n",
    "\n",
    "# Schedule the message to be sent every hour\n",
    "schedule.every().minute.do(fetch_transform_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7880\\3305108932.py:52: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result_df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
